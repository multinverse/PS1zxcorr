{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acessar o servidor do PS1 olhe os sites:\n",
    "\n",
    "http://ps1images.stsci.edu/ps1_dr2_query.html\n",
    "\n",
    "http://ps1images.stsci.edu/ps1_dr2_api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abaixo estão os inputs\n",
    "\n",
    "NSIDE\n",
    "para a resolução\n",
    "\n",
    "$\\textbf{constraints}$\n",
    "\n",
    "$\\mathit{use:}$\n",
    "- True para usar as restrições;\n",
    "- False, caso contrário.\n",
    "\n",
    "$\\mathit{type:}$\n",
    "- galaxy: para extrair galáxias\n",
    "- star: para extrair estrelas\n",
    "- qualquer outra input não usa esta restrição\n",
    "\n",
    "\n",
    "$\\mathit{band:}$ para selecionar a banda da restrição\n",
    "- g, r, i, z e y\n",
    "\n",
    "\n",
    "$\\textbf{params\\_flags}$\n",
    "\n",
    "- $\\mathit{use:}$ True para usar as restrições de flags;\n",
    "- $\\mathit{table:}$ usar a 1 = DetectionFlags, 2 = DetectionFlags2 ou 3 = DetectionFlags3.\n",
    "- $\\mathit{band:}$ se refere ao uso da table numa dada banda (g, r, i, z ou y). Isto é importante para is dados que vem classificados em: ginfoFlags, ginfoFlags2, ginfoFlags3, iinfoFlags, iinfoFlags2, iinfoFlags3, rinfoFlags, rinfoFlags2, rinfoFlags3,...\n",
    "\n",
    "$\\textbf{params\\_strips}$\n",
    "\n",
    "- $\\mathit{dec\\ strips:}$ True: se for restringir a coleta (em declination), False caso contrário.\n",
    "- $\\mathit{dec\\ center:}$ O centro (em graus) da strip\n",
    "- $\\mathit{dec\\ width :}$ comprimento da strip \n",
    " \n",
    "$\\textbf{hexa\\_query}$\n",
    "- o hexadecimal que contêm os flags a serem ativados de uma das três tabelas.\n",
    "\n",
    "$\\textbf{restart:}$\n",
    "- Caso False, ele não iniciará do primeiro arquivo, mas sim do último arquivo existente.\n",
    "- OBS: Caso mude a strip a ser utilizada é preciso deixar True, de forma ao código limpar o diretório e usar somente, para o dado NSIDE, os arquivos desejados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSIDE         = 4*256\n",
    "constraints   = {\"use\":False, \"type\":\"galaxy\", \"band\": \"r\"} \n",
    "params_flags  = {\"use\":True, \"table\":1, \"band\":\"r\"}\n",
    "params_strips = {'dec strips':True,'dec center':-15.,'dec width': 15}\n",
    "hexa_query    = 0x1003bc88\n",
    "restart       = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar bibliotecas --- Aqui começa o código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mastcasjobs\n",
    "import casjobs\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import requests\n",
    "import requests.exceptions\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "from astropy.io import ascii, fits\n",
    "from astropy.table import Table, join, hstack, vstack\n",
    "from time import time,strftime, gmtime\n",
    "\n",
    "import os, sys, re\n",
    "import pylab\n",
    "import json\n",
    "\n",
    "#import flags\n",
    "\n",
    "try: # Python 3.x\n",
    "    from urllib.parse import quote as urlencode\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:  # Python 2.x\n",
    "    from urllib import pathname2url as urlencode\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "try: # Python 3.x\n",
    "    import http.client as httplib \n",
    "except ImportError:  # Python 2.x\n",
    "    import httplib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dê como string o usuário e a senha\n",
    "user      = \"1112277644\"\n",
    "pwd       = \"Feymann@1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "if not os.environ.get('CASJOBS_WSID'):\n",
    "    os.environ['CASJOBS_WSID'] = user\n",
    "if not os.environ.get('CASJOBS_PW'):\n",
    "    os.environ['CASJOBS_PW'] = pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificar qual o NSIDE mínimo para a conexão de internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxnside():\n",
    "    theta,phi = 0.,0.#degree\n",
    "    nsides = [2**x for x in range(12)][1:]\n",
    "    nsides = np.flip(nsides)\n",
    "    for nside in nsides:\n",
    "        pix = hp.ang2pix(nside,theta = theta,phi = phi, lonlat=True) \n",
    "        ang, radius = parameters(nside,pix)\n",
    "        query = query_string(theta,phi,radius)\n",
    "        jobs  = mastcasjobs.MastCasJobs(context=\"PanSTARRS_DR2\")\n",
    "    \n",
    "        try:\n",
    "            jobs.quick(query, task_name=\"python cone search\")\n",
    "            pass\n",
    "        except Exception:\n",
    "            return nside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estabelecer conexão com o PS1\n",
    "\n",
    "As funções abaixo servem para estabelecer a conexão com o servidor do PS1 e extrair os dados com a $\\textbf{query}$ desejada.\n",
    "\n",
    "$\\textbf{parameters:}$ \n",
    "- input: recebe o $\\mathit{nside}$ (a resolução) e o $\\mathit{pixel}$ que será extraído os dados;\n",
    "- output: devolve os angulos do centro do pixel e o raio do centro ao vértice mais distante deste.\n",
    "\n",
    "$\\textbf{query\\_strings:}$ \n",
    "- input: recebe os ângulos do centrais, $\\mathit{ang0}$ ($\\theta = dec$) e $\\mathit{ang1}$ ($\\phi =ra$), e o raio de coleta de dados;\n",
    "- output: a $\\mathit{query}$ para comunicar com o servidor.\n",
    "\n",
    "$\\textbf{query\\_function:}$ \n",
    "- input: $\\mathit{params}$ que contêm as informações gerais da coleta de dados e $\\mathit{constraints}$ que define as restrições;\n",
    "- output: a tabela já sob constraints.\n",
    "\n",
    "Ele estabelecerá a conexão com o PS1 e tentará extrair os dados brutos na região do céu definida. Caso a quantidade de dados seja muito alta, será tratado em uma outra parte do código. Caso não, ao extrair os dados este são estabelecidos numa tabela ascii e selecionado somente os objetos que satisfazem a constraints.\n",
    "\n",
    "$\\textbf{query_constraints:}$ \n",
    "- input: $\\mathit{table}$ com os dados do PS1 e $\\mathit{constraints}$ que define as restrições;\n",
    "- output: tabela com os dados que satisfazem o constraints.\n",
    "\n",
    "Ele receberá se haverá separação de galaxias ou de estrelas, ou nenhum dos dois. No caso de ter constraints mas não ter especificação do tipo de objeto, só haverá restrição dos valores dos angulos e das magnitudes (na dada banda) serem >-999. No caso, de não usar restrição, para que seja possível armazenar os dados nos padrões do código, só serão aplicadas as restrições angulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixcolnames(tab):\n",
    "    \"\"\"Fix column names returned by the casjobs query\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tab (astropy.table.Table): Input table\n",
    "\n",
    "    Returns reference to original table with column names modified\"\"\"\n",
    "\n",
    "    pat = re.compile(r'\\[(?P<name>[^[]+)\\]')\n",
    "    for c in tab.colnames:\n",
    "        m = pat.match(c)\n",
    "        if not m:\n",
    "            raise ValueError(\"Unable to parse column name '{}'\".format(c))\n",
    "        newname = m.group('name')\n",
    "        tab.rename_column(c,newname)\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters(nside,pixel):\n",
    "    radius = hp.pixelfunc.max_pixrad(nside, degrees=True)*3600\n",
    "    angles = hp.pix2ang(nside,int(pixel), nest = False, lonlat=True)\n",
    "    return angles, radius\n",
    "    \n",
    "\n",
    "def query_string(ang0,ang1,radius):\n",
    "        query = \"\"\"select sot.objID, sot.uniquePspsSTid, sot.ippObjID, sot.surveyID, sot.tessID, sot.projectionID, sot.skyCellID, sot.randomStackObjID, sot.primaryDetection, sot.bestDetection, sot.dvoRegionID, sot.processingVersion,\n",
    " sot.gippDetectID, sot.gstackDetectID, sot.gstackImageId, sot.gra, sot.gdec, sot.graErr, sot.gdecErr, sot.gEpoch, sot.gPSFMag, sot.gPSFMagErr, sot.gApMag, sot.gApMagErr, sot.gKronMag, sot.gKronMagErr, sot.ginfoFlag, sot.ginfoFlag2, sot.ginfoFlag3, sot.gnFrames,\n",
    " sot.rippDetectID, sot.rstackDetectID, sot.rstackImageId, sot.rra, sot.rdec, sot.rraErr, sot.rdecErr, sot.rEpoch, sot.rPSFMag, sot.rPSFMagErr, sot.rApMag, sot.rApMagErr, sot.rKronMag, sot.rKronMagErr, sot.rinfoFlag, sot.rinfoFlag2, sot.rinfoFlag3, sot.rnFrames,\n",
    " sot.iippDetectID, sot.istackDetectID, sot.istackImageId, sot.ira, sot.idec, sot.iraErr, sot.idecErr, sot.iEpoch, sot.iPSFMag, sot.iPSFMagErr, sot.iApMag, sot.iApMagErr, sot.iKronMag, sot.iKronMagErr, sot.iinfoFlag, sot.iinfoFlag2, sot.iinfoFlag3, sot.inFrames,\n",
    " sot.zippDetectID, sot.zstackDetectID, sot.zstackImageId, sot.zra, sot.zdec, sot.zraErr, sot.zdecErr, sot.zEpoch, sot.zPSFMag, sot.zPSFMagErr, sot.zApMag, sot.zApMagErr, sot.zKronMag, sot.zKronMagErr, sot.zinfoFlag, sot.zinfoFlag2, sot.zinfoFlag3, sot.znFrames,\n",
    " sot.yippDetectID, sot.ystackDetectID, sot.ystackImageId, sot.yra, sot.ydec, sot.yraErr, sot.ydecErr, sot.yEpoch, sot.yPSFMag, sot.yPSFMagErr, sot.yApMag, sot.yApMagErr, sot.yKronMag, sot.yKronMagErr, sot.yinfoFlag, sot.yinfoFlag2, sot.yinfoFlag3, sot.ynFrames\n",
    " \n",
    "\n",
    " from fGetNearbyObjEq(\"\"\"+\",\".join([str(ang0),str(ang1),str(radius/60.)])+\"\"\") nb\n",
    " inner join StackObjectThin sot on sot.objid=nb.objid\n",
    "\n",
    " where sot.primaryDetection = 1 \n",
    "\"\"\" \n",
    "        return query\n",
    "\n",
    "def query_function(params, constraints):\n",
    "    params['ang'],params['r'] = parameters(params[\"NSIDE\"],params['pixel'])    \n",
    "    query   =  query_string(params['ang'][0],params['ang'][1],params['r'])\n",
    "    jobs    = mastcasjobs.MastCasJobs(context=\"PanSTARRS_DR2\")\n",
    "    \n",
    "    try:\n",
    "        table = jobs.quick(query, task_name=\"python cone search\")\n",
    "    except Exception:\n",
    "        print(\"Exception. code!=200\")\n",
    "        table =  handling_exception(params,constraints)\n",
    "        print(\"Extracted {} objects from PS1\".format(len(table)))\n",
    "        return table, jobs  \n",
    "\n",
    "    table = fixcolnames(ascii.read(table))\n",
    "    table = query_constraints(table, constraints)\n",
    "    return table, jobs\n",
    "\n",
    "def query_constraints(table,constraints):\n",
    "    band_KronMag = table[''.join([constraints[\"band\"],'KronMag'])]\n",
    "    band_PSFMag  = table[''.join([constraints[\"band\"],'PSFMag'])]\n",
    "\n",
    "    if constraints['use']:\n",
    "        if constraints[\"type\"]==\"galaxy\":\n",
    "            constraint = (band_KronMag - band_PSFMag) + 0.192 - 0.120*(band_KronMag - 21.) - 0.018*(band_KronMag - 21.)*(band_KronMag - 21.)\n",
    "            list1 = np.where((table['gdec']>-999)*(table['gra']>-999)*(band_KronMag>-999)*(band_PSFMag>-999)*(constraint>0))  \n",
    "        \n",
    "        elif constraints[\"type\"]==\"star\":\n",
    "            constraint = (band_KronMag - band_PSFMag) + 0.192 - 0.120*(band_KronMag - 21.) - 0.018*(band_KronMag - 21.)*(band_KronMag - 21.)\n",
    "            list1 = np.where((table['gdec']>-999)*(table['gra']>-999)*(band_KronMag>-999)*(band_PSFMag>-999)*(constraint<0))\n",
    "        \n",
    "        else:    \n",
    "            list1 = np.where((table['gdec']>-999)*(table['gra']>-999)*(band_KronMag>-999)*(band_PSFMag>-999))\n",
    "    else:\n",
    "        list1 = np.where((table['gdec']>-999)*(table['gra']>-999))\n",
    "    \n",
    "    return table[list1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abaixo temos duas funções.\n",
    "\n",
    "$\\textbf{file\\_verification:}$ Ele verificará se há arquivo com o mesmo nome do arquivo \".fits\" a ser gerado, no diretório FITS (caso não exista, ele criará este). Se tiver o arquivo, ele apaga para poder substituir. Caso não exista ele não faz nada.\n",
    "\n",
    "$\\textbf{galaxies\\_pixel:}$ Como coletamos dados a partir de um raio r, devemos tomar um r tal que englobe todo pixel no momento de coletar os dados. Coletado, devemos verificar quais galáxias tem angulos que realmente se encontram no pixel desejado, os que não estiverem serão descartados.\n",
    "\n",
    "Se as funções do healpy estiverem com $\\textbf{lonlat}=True$ então as entradas (ou saídas) serão dadas (longitude,latitude), se for $False$, (colatitude,longitude).\n",
    "\n",
    "$False$ \n",
    "\n",
    "$\\textbf{colatitude:}\\ \\theta \\in (0,\\pi)$, com $0$ no polo norte.\n",
    "\n",
    "$\\textbf{longitude:}\\ \\phi \\in (0,2\\pi)$, com $0$ no polo norte. O $0$ está no centro do mapa e o ângulo aumenta para a esquerda (oeste) do mapa.\n",
    "\n",
    "$True$ \n",
    "\n",
    "$\\textbf{longitude:}\\ \\theta \\in (0,2\\pi)$, com $0$ no polo norte. O $0$ está no centro do mapa e o ângulo aumenta para a esquerda (oeste) do mapa.\n",
    "\n",
    "$\\textbf{latitude:}\\ \\phi \\in (-\\pi/2,\\pi/2)$, com $\\pi/2$ no polo norte.\n",
    "\n",
    "$\\textbf{name2pixel:}$ Recebe uma string com o nome do arquivo e só devolve a parte que contem o pixel, como um inteiro.\n",
    "\n",
    "$\\textbf{lastpix:}$ Recebe o NSIDE que está sendo rodado o código e verifica se há fits para este nside, caso sim, fornece o último pixel que há no diretório. O programa rodará a partir deste último pixel pois ele pode estar corrompido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_verification(path,file,nside):\n",
    "    if os.path.isdir(path):#verifica se existe /FITS\n",
    "        path = os.path.join(path,str(nside)) #.../FITS --> .../FIT/NPIX\n",
    "        if os.path.isdir(path): # verifica se existe /NPIX\n",
    "            path = os.path.join(path,file) #nome da path do arquivo\n",
    "            if os.path.isfile(path): #se existir arquivo com o nome é apagado\n",
    "                os.remove(path)\n",
    "        else:\n",
    "            os.mkdir(path)\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "        os.mkdir(os.path.join(path,str(nside)))\n",
    "\n",
    "def galaxies_pixel(table,params):\n",
    "    list1 = np.where(hp.ang2pix(params['NSIDE'],table['gra'],table['gdec'], lonlat=True) == params['pixel'])\n",
    "    tab   = table[list1]\n",
    "    print(\"Number of galaxies: {}\".format(len(tab)))\n",
    "    return  tab\n",
    "\n",
    "def name2pixel(name):\n",
    "\tpix = int(name.split(\"_\")[-1].split(\".\")[0])\n",
    "\treturn pix\n",
    "\n",
    "def lastpix(nside, wpix=\"last\"): #wpix = what pixel?\n",
    "\tpath      = os.getcwd()\n",
    "\tpathfits  = os.path.join(path,\"FITS\",str(nside))\n",
    "\ttry:\n",
    "\t\tfiles     = os.listdir(pathfits)\n",
    "\t\tpaths     = [os.path.join(pathfits,name) for name in files]\n",
    "\t\tnfits     = len(paths)\n",
    "\t\t\n",
    "\t\tif   wpix == \"last\":\n",
    "\t\t\tlastfits  = max(paths, key=os.path.getctime)\n",
    "\t\t\tprint(\"There are {} fits files in : {}\".format(nfits,pathfits))\n",
    "\t\t\tlast      = name2pixel(lastfits)\n",
    "\t\t\tprint(\"The last pix in directory is: {}\".format(last))\n",
    "\t\t\treturn last\n",
    "\t\telif wpix == \"first\":\n",
    "\t\t\tfirstfits = min(paths, key=os.path.getctime)\n",
    "\t\t\tprint(\"There are {} fits files in : {}\".format(nfits,pathfits))\n",
    "\t\t\tfirst     = name2pixel(firstfits)\n",
    "\t\t\tprint(\"The first pix in directory is: {}\".format(first)) \n",
    "\t\t\treturn first\n",
    "\t\telse:\n",
    "\t\t\traise Exception(\"Invalid command.\")\n",
    "\texcept:\n",
    "\t\tprint(\"There aren't files in: {}\".format(pathfits))\n",
    "\t\treturn False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLAGS\n",
    "\n",
    "Transforma o Hexadecimal usado em binário e verifica quais flags (de uma das três tabelas) são ativadas, e quais dados satisfazem-nas.\n",
    "\n",
    "$\\textbf{hexa2bin:}$ transforma um hexadecimal em binário.\n",
    "\n",
    "$\\textbf{flags\\_verification:}$ \n",
    "- input: $\\mathit{params\\_flags}$ que contêm as informações gerais das flags como se será usada, qual das tabelas flags e em que banda. $\\mathit{params_hexa}$ fornece o tamanho do hexadecimal (em binario) e ele como binario;\n",
    "- output: as flags da tabela que são ativadas.\n",
    "\n",
    "$\\textbf{hexa2flags:}$ \n",
    "- input: $\\mathit{hexa}$ hexadecimal de restrição, $\\mathit{file\\_names}$ o nome do arquivo com os nomes das flags e $\\mathit{file\\_datas}$ com o nome do arquivo com os valores das flags;\n",
    "- output: retorna os dados que não tem os flags ativados..\n",
    "\n",
    "\n",
    "recebe um (hexa)decimal e devolve as flags ativadas, duma certa tabela de flags.\n",
    "\n",
    "$\\textbf{accept\\_data:}$ \n",
    "- input: $\\mathit{flags\\_table}$ as flags a serem verificadas e $\\mathit{flags\\_input}$ as flags do objeto;\n",
    "- output: se não há flag ativada pelo objeto, das flags selecionadas pela hexadecimal inicial, o objeto é aceito, caso contrário descartado.\n",
    "\n",
    "\n",
    "$\\textbf{flags\\_constraints:}$ \n",
    "- input: $\\mathit{tab}$ tabela com os dados dos objetos, $\\mathit{hexa\\_query}$ com a hexadecimal exigida e $\\mathit{params}$ com dados gerais da extração;\n",
    "- output: tabela somente com os dados que não ativam nenhuma flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex2bin(hexa):\n",
    "    return bin(int(hexa))[2:]\n",
    "\n",
    "def flags_verification(params_flags, params_hexa): #verifica quais as flags ativadas\n",
    "    flags = []\n",
    "    for i in range(params_flags['num flags']):\n",
    "        bin_flagi = hex2bin(params_flags['datas'][i])\n",
    "        len_flagi = len(bin_flagi)\n",
    "        \n",
    "        for j in range(len_flagi):\n",
    "            bin_q = params_hexa['binary hexa'][-j-1]\n",
    "            bin_f = bin_flagi[-j-1]\n",
    "            if bin_f==\"1\" and bin_q==\"1\":\n",
    "                flags = np.append(flags,params_flags['names'][i][:-1])\n",
    "                #print(\"\\nTable       : Detection{}\\nFLAG ativada: {}POS_FLAG    : {}\".format(params_flags['file'][:-4],params_flags['names'][i],i))\n",
    "                break\n",
    "        if len_flagi+1>params_hexa['length hexa']: return flags#break\n",
    "        \n",
    "def hexa2flags(hexa,file_names,file_datas): #recebe um (hexa)decimal e devolve as flags ativadas, duma certa tabela de flags\n",
    "    bin_query = hex2bin(hexa)\n",
    "    len_query = len(bin_query)\n",
    "    \n",
    "    file_names = os.path.join(\"FLAGS\",file_names)\n",
    "    file_datas = os.path.join(\"FLAGS\",file_datas)\n",
    "    \n",
    "    file_     = open(file_names,'r')\n",
    "    names     = file_.readlines()\n",
    "    file_.close()\n",
    "    datas     = np.loadtxt(file_datas)\n",
    "    num_flags = len(datas)\n",
    "    \n",
    "    params_flags = {\"names\":names, \"file\":file_names,\"datas\":datas,\"num flags\":num_flags}\n",
    "    params_hexa  = {\"length hexa\":len_query, \"binary hexa\":bin_query}\n",
    "    \n",
    "    return flags_verification(params_flags,params_hexa)\n",
    "\n",
    "def accept_data(flags_table, flags_input):\n",
    "    if set(flags_input).intersection(set(flags_table))==set():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def flags_constraints(tab,hexa_query,params):\n",
    "    \n",
    "    file_names = \"\".join((\"FLAGS\",str(params[\"table\"]),\".txt\"))\n",
    "    file_datas = \"\".join((\"DATA_FLAGS\",str(params[\"table\"]),\".txt\"))\n",
    "    \n",
    "    params[\"bands\"] = [\"g\",\"r\",\"i\",\"z\",\"y\"]\n",
    "    lbands          = len(params[\"bands\"])\n",
    "    flags_query     = hexa2flags(hexa_query,file_names,file_datas)\n",
    "    \n",
    "    if params[\"table\"]: flag_tab = tab[\"\".join((params[\"bands\"][0],\"infoFlag\"))]\n",
    "    else: flag_tab = tab[\"\".join((params[\"bands\"][0],\"infoFlag\",str(params[\"table\"])))]\n",
    "    pos = []\n",
    "    \n",
    "    for j in range(len(flag_tab)):\n",
    "        flags_tab    = hexa2flags(flag_tab[j],file_names,file_datas)\n",
    "        if accept_data(flags_tab,flags_query): pos = np.append(pos,j)\n",
    "        else: pass\n",
    "    \n",
    "    if lbands-1:           \n",
    "        for i in range(lbands-1): \n",
    "            i+=1\n",
    "            if params[\"table\"]: flag_tab = tab[\"\".join((params[\"bands\"][i],\"infoFlag\"))]\n",
    "            else: flag_tab = tab[\"\".join((params[\"bands\"][i],\"infoFlag\",str(params[\"table\"])))]\n",
    "            pos2 = []\n",
    "            for j in range(len(flag_tab)):\n",
    "                flags_tab    = hexa2flags(flag_tab[j],file_names,file_datas)\n",
    "                if accept_data(flags_tab,flags_query):\n",
    "                    pos2 = np.append(pos2,j)\n",
    "                else: pass\n",
    "            pos = set(pos).intersection(set(pos2))\n",
    "    pos = map(int,list(pos))\n",
    "    return  tab[pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strips\n",
    "Selecionar os pixels dentro de um strip\n",
    "\n",
    "\n",
    "$\\textbf{range\\_dec:}$ \n",
    "\n",
    "$\\mathit{params}$ com as informção se será utilizada a restrição em dec e se sim, dá o intervalo desta restrição;\n",
    "\n",
    "\n",
    "$\\textbf{pixelstrips:}$ \n",
    "- input: $\\mathit{params}$ com as informção se será utilizada a restrição em dec e se sim, dá o intervalo desta restrição;\n",
    "- output: os pixels a serem extraido dados, que estão dentro da strip.\n",
    "\n",
    "$\\textbf{col2dec:}$ converte colatitude em declination (deg_out=True a saida será em graus, caso contrario em radianos)\n",
    "\n",
    "$\\textbf{dec2col:}$ converte declination em colatitude (deg_out=True a saida será em graus, caso contrario em radianos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_dec(params):\n",
    "    if params['dec strips']:\n",
    "        return params['dec center'] - params['dec width']/2.,params['dec center'] + params['dec width']/2.\n",
    "    else:\n",
    "        return [-90.,90.]\n",
    "    \n",
    "def pixelstrips(params):\n",
    "    dec1,dec0 = range_dec(params)\n",
    "    \n",
    "    nside     = params['NSIDE']\n",
    "    theta_min = np.array(dec2col(dec1))\n",
    "    theta_max = np.array(dec2col(dec0))\n",
    "    pix = []\n",
    "    if theta_min.size==1:\n",
    "        pix = np.append(pix,hp.query_strip(nside,theta_max,theta_min, inclusive=True))\n",
    "    else:\n",
    "        for i in range(theta_min.size):\n",
    "            pix = np.append(pix,hp.query_strip(nside,theta_max[i],theta_min[i], inclusive=True))\n",
    "    return pix.astype(int)\n",
    "\n",
    "def col2dec(colat=None, deg_out=False):\n",
    "    colat = np.array(colat)\n",
    "    ones  = np.ones(colat.size)\n",
    "    \n",
    "    down = np.where(colat<0)[0]\n",
    "    up   = np.where(colat>180)[0]\n",
    "    \n",
    "    if (down.size+up.size)==0:\n",
    "        if deg_out:\n",
    "            return -(colat - 90.)\n",
    "        else:\n",
    "            return np.radians(-(colat - 90.))\n",
    "    else: print(\"Error\")\n",
    "        \n",
    "def dec2col(dec=None, deg_out=False):\n",
    "    dec  = np.array(dec)\n",
    "    ones = np.ones(dec.size)\n",
    "    \n",
    "    down = np.where(dec<-90)[0]\n",
    "    up   = np.where(dec>90)[0]\n",
    "    \n",
    "    if (down.size+up.size)==0:\n",
    "        if deg_out:\n",
    "            return -(dec - 90.)\n",
    "        else:\n",
    "            return np.radians(-(dec - 90.))\n",
    "    else: \n",
    "        print(\"Error\")\n",
    "\n",
    "def newtrips(strips,pix):\n",
    "\t\n",
    "\twispix = np.where(strips==pix)[0] #wispix = where is pix?\n",
    "\twispix = int(wispix)\n",
    "\treturn strips[wispix:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratando exceções\n",
    "\n",
    "Esta parte tratará dos casos em que dá erro de servidor, ou seja, o tamanho dos arquivos são muito grandes. Isto ocorre quando o NSIDE é relativamente baixo, ou seja, a resolução é alta (o tamanho do pixel é grande).\n",
    "A ideia é verificar de antemão quando vai ocorrer um erro, \"quebrar\" o pixel em pixels menores e coletar os dados em pixels menores (com raio menor). Após ter os dados, juntar os pixels em um único pixel e verificar quais dados realmente estão no pixel e quais não estão.\n",
    "\n",
    "Para isto ser efetivo, foi criado uma função $\\textbf{maxnside()}$ que identifica qual o NSIDE que dará problema de conexão (devido a conexão utilizada). Com esta informação, crio uma variável $\\textbf{NSIDEmax}$ como sendo $4*\\textbf{maxnside()}$, que seria o NSIDE que a conexão certamente não dará problema. O fator é $2^2 =4$ pois, para $2$ pode ser que exista pixels que deem problema, mas não deram pois a verificação é feita na região central $(\\theta,\\phi)=(0,0)$.\n",
    "\n",
    "Assim, quando o código acusar $\\textbf{Exception}$ no dado pixel, ou seja, quando a quantidade de dados a serem extraidos do servidor for muito alto, o pixel é \"quebrado\" em pixels menores ($\\textbf{NSIDEmax}$) que cobrem o pixel e os dados são extraidos em pixels menores. Ao final da extração, faz-se uma verificação quais dados de fato pertencem ao pixel original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handling_exception(params,constraints):\n",
    "    NSIDEmax = params['NSIDE max']\n",
    "    vec      = hp.ang2vec(params[\"ang\"][0],params[\"ang\"][1], lonlat=True)\n",
    "    pixels   = hp.query_disc(NSIDEmax,vec,radians(params['r']/3600.), inclusive= True)\n",
    "    subjobs  = mastcasjobs.MastCasJobs(context=\"PanSTARRS_DR2\")\n",
    "    \n",
    "    for pixel in pixels:\n",
    "        ang,r     = parameters(NSIDEmax,pixel)\n",
    "        subquery  = sub_query_string(ang[0],ang[1],r)\n",
    "        accept    = True\n",
    "        \n",
    "        while accept:\n",
    "            try:\n",
    "                subtab = subjobs.quick(subquery, task_name=\"python cone search\")\n",
    "                accept = False\n",
    "            except Exception:\n",
    "                time.sleep(60)\n",
    "                pass\n",
    "   \n",
    "        subtab    = fixcolnames(ascii.read(subtab))\n",
    "        subtab    = query_constraints(subtab, constraints)\n",
    "        \n",
    "        if pixel == pixels[0]:\n",
    "            table = subtab\n",
    "        else:\n",
    "            table = vstack([table,subtab])\n",
    "\n",
    "    return table\n",
    "\n",
    "def sub_query_string(ang0,ang1,r):\n",
    "        query = \"\"\"select sot.objID, sot.uniquePspsSTid, sot.ippObjID, sot.surveyID, sot.tessID, sot.projectionID, sot.skyCellID, sot.randomStackObjID, sot.primaryDetection, sot.bestDetection, sot.dvoRegionID, sot.processingVersion,\n",
    " sot.gippDetectID, sot.gstackDetectID, sot.gstackImageId, sot.gra, sot.gdec, sot.graErr, sot.gdecErr, sot.gEpoch, sot.gPSFMag, sot.gPSFMagErr, sot.gApMag, sot.gApMagErr, sot.gKronMag, sot.gKronMagErr, sot.ginfoFlag, sot.ginfoFlag2, sot.ginfoFlag3, sot.gnFrames,\n",
    " sot.rippDetectID, sot.rstackDetectID, sot.rstackImageId, sot.rra, sot.rdec, sot.rraErr, sot.rdecErr, sot.rEpoch, sot.rPSFMag, sot.rPSFMagErr, sot.rApMag, sot.rApMagErr, sot.rKronMag, sot.rKronMagErr, sot.rinfoFlag, sot.rinfoFlag2, sot.rinfoFlag3, sot.rnFrames,\n",
    " sot.iippDetectID, sot.istackDetectID, sot.istackImageId, sot.ira, sot.idec, sot.iraErr, sot.idecErr, sot.iEpoch, sot.iPSFMag, sot.iPSFMagErr, sot.iApMag, sot.iApMagErr, sot.iKronMag, sot.iKronMagErr, sot.iinfoFlag, sot.iinfoFlag2, sot.iinfoFlag3, sot.inFrames,\n",
    " sot.zippDetectID, sot.zstackDetectID, sot.zstackImageId, sot.zra, sot.zdec, sot.zraErr, sot.zdecErr, sot.zEpoch, sot.zPSFMag, sot.zPSFMagErr, sot.zApMag, sot.zApMagErr, sot.zKronMag, sot.zKronMagErr, sot.zinfoFlag, sot.zinfoFlag2, sot.zinfoFlag3, sot.znFrames,\n",
    " sot.yippDetectID, sot.ystackDetectID, sot.ystackImageId, sot.yra, sot.ydec, sot.yraErr, sot.ydecErr, sot.yEpoch, sot.yPSFMag, sot.yPSFMagErr, sot.yApMag, sot.yApMagErr, sot.yKronMag, sot.yKronMagErr, sot.yinfoFlag, sot.yinfoFlag2, sot.yinfoFlag3, sot.ynFrames\n",
    " \n",
    "\n",
    " from fGetNearbyObjEq(\"\"\"+\",\".join([str(ang0),str(ang1),str(r/60.)])+\"\"\") nb\n",
    " inner join StackObjectThin sot on sot.objid=nb.objid\n",
    "\n",
    " where sot.primaryDetection = 1 \n",
    "\"\"\" \n",
    "\n",
    "        return query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escrever e ler arquivo \".fits\" dos dados óticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fits(table,params):\n",
    "    file = \"_\".join((\"PixelFit\",str(params['NSIDE']),str(int(params['pixel']))))\n",
    "    file = \".\".join((file,\"fits\"))\n",
    "    path = os.getcwd()\n",
    "    path = os.path.join(path,\"FITS\")\n",
    "    file_verification(path,file,params['NSIDE'])\n",
    "    path = os.path.join(path,str(params['NSIDE']))\n",
    "    table.write(os.path.join(path,file))\n",
    "\n",
    "    \n",
    "def read_fit(params): \n",
    "    #params = {\"NSIDE\":NSIDE, 'pixel':pix, \"NPIX\":NPIX}\n",
    "    params['ang'] = hp.pix2ang(params['NSIDE'],int(params['pixel']), nest = True, lonlat=True)\n",
    "    file_name = \"_\".join([\"PixelFit\",str(params['NSIDE']),str(params['pixel'])])\n",
    "    file_name = \".\".join([file_name,\"fits\"])\n",
    "    \n",
    "    tab = Table.read(os.path.join(\"FITS\",str(params['NSIDE']),file_name))\n",
    "\n",
    "    return tab, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O programa começa a partir daqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSIDE      : 1024\n",
      "Num. Pixels: 12582912\n",
      "NSIDE   max: 1024\n"
     ]
    }
   ],
   "source": [
    "NPIX   = hp.nside2npix(NSIDE)\n",
    "params = {\"NSIDE\":NSIDE, \"NPIX\":NPIX} \n",
    "params[\"NSIDE max\"] = 8*maxnside()\n",
    "params_strips['NSIDE']=params['NSIDE']\n",
    "print( \"NSIDE      : {}\".format(params['NSIDE']))\n",
    "print( \"Num. Pixels: {}\".format(params['NPIX']))\n",
    "print( \"NSIDE   max: {}\".format(params['NSIDE max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 fits files in : /home/marins/Documentos/Programmation/PS1zxcorr/notebook/FITS/1024\n",
      "The last pix in directory is: 7108615\n",
      "12.66% of the sky covered.\n"
     ]
    }
   ],
   "source": [
    "strips = pixelstrips(params_strips) if params_strips['dec strips'] else np.arange(params['NPIX'])\n",
    "if not restart:\n",
    "\tlast   = lastpix(NSIDE,\"last\")\n",
    "\tif last:\n",
    "\t\tstrips = newtrips(strips,last)\n",
    "\telse: pass\t\n",
    "print(\"{:.2f}% of the sky covered.\".format(100*float(len_strips)/params['NPIX']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of galaxies: 125\n",
      "Program's time (hh:mm:ss): 00:00:02\n",
      "Pixel 7108615\n",
      "0.00% completed program\n",
      " \n",
      "\n",
      "Number of galaxies: 140\n",
      "Program's time (hh:mm:ss): 00:00:02\n",
      "Pixel 7108616\n",
      "0.00% completed program\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for num,pix in enumerate(strips):    \n",
    "    timei     = time()\n",
    "    theta,phi = hp.pix2ang(params['NSIDE'],pix, lonlat=True, nest=False)\n",
    "    \n",
    "    params['pixel'] = pix\n",
    "    tab, job        = query_function(params, constraints)\n",
    "    tab             = galaxies_pixel(tab,params)\n",
    "    tab             = flags_constraints(tab,hexa_query,params_flags)\n",
    "    write_fits(tab,params)\n",
    "    \n",
    "    \n",
    "    timef    = strftime('%H:%M:%S', gmtime(time()-timei))\n",
    "    print(\"Program's time (hh:mm:ss): {}\".format(timef))\n",
    "    print(\"Pixel {}\".format(pix))\n",
    "    print(\"{:.2f}% completed program\\n \\n\".format(100*(float(num+1)/len_strips)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
